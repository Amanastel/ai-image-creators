# ğŸ¨ AI Creative Pipeline

An advanced AI-powered creative pipeline that transforms text descriptions into stunning images and 3D models, powered by local LLM technology and the Openfabric SDK.

## âœ¨ Features

- ğŸ¤– **Local LLM Integration**: Uses LLaMA 2 for intelligent prompt expansion
- ğŸ¨ **Text-to-Image Generation**: Creates high-quality images from text descriptions
- ğŸŒŸ **Image-to-3D Conversion**: Transforms 2D images into interactive 3D models
- ğŸ’¾ **Smart Memory System**: Maintains context and history across sessions
- ğŸ”’ **Privacy-Focused**: All processing happens locally
- ğŸ¯ **Multiple Artistic Styles**: Supports realistic, artistic, minimalist, and fantasy styles
- ğŸ“Š **Comprehensive Logging**: Detailed execution logs and error tracking

## ğŸš€ Prerequisites

- Python 3.8 or higher
- Poetry for dependency management
- LLaMA 2 7B Chat model (GGUF format)
- 8GB+ RAM recommended
- NVIDIA GPU (optional, for faster processing)

## ğŸ“¦ Installation

1. Clone the repository:
```bash
git clone https://github.com/Amanastel/ai-image-creator.git
cd ai-image-creator
```

2. Install dependencies:
```bash
poetry install
```

3. Download the LLaMA 2 7B Chat model:
```bash
mkdir -p models
# Download llama-2-7b-chat.gguf from Hugging Face
# Place it in the models directory
```

4. Create required directories:
```bash
mkdir -p outputs memory
```

## ğŸ› ï¸ Configuration

1. Environment Setup:
   - Copy `.env.example` to `.env`
   - Adjust memory settings if needed
   - Configure GPU settings (optional)

2. Model Configuration:
   - Default model: LLaMA 2 7B Chat
   - Supports other GGUF format models
   - Configurable inference parameters

## ğŸ–¥ï¸ Running the Application

### Method 1: Using Start Script
```bash
./start.sh
```

### Method 2: Using Docker
```bash
docker build -t ai-creative-pipeline .
docker run -p 8888:8888 -v $(pwd)/outputs:/app/outputs -v $(pwd)/memory:/app/memory ai-creative-pipeline
```

Access the application at: http://localhost:8888/swagger-ui/#/App/post_execution

## ğŸ“ Usage Guide

### Basic Usage

1. Access the Swagger UI
2. Navigate to POST /execution endpoint
3. Click "Try it out"
4. Submit a prompt:
```json
{
  "prompt": "Make me a glowing dragon standing on a cliff at sunset",
  "style": "fantasy",
  "dimensions": {
    "width": 1024,
    "height": 768
  },
  "quality": 95
}
```

### Advanced Options

- **Styles**: 
  - `realistic`: Photo-realistic images
  - `artistic`: Creative interpretations
  - `minimalist`: Clean, simple designs
  - `fantasy`: Magical and otherworldly scenes

- **Quality Settings**:
  - Resolution: Up to 2048x2048
  - Quality: 1-100 scale
  - Format: PNG/JPG/JPEG

## ğŸ§  Memory System

### Short-Term Memory
- Maintains context during interactions
- Enables coherent conversation flow
- Temporary storage in Redis (optional)

### Long-Term Memory
- JSON-based persistent storage
- Searchable history
- Entry format:
```json
{
  "timestamp": "2025-04-16T23:33:12.341825",
  "original_prompt": "glowing dragon on cliff",
  "expanded_prompt": "A majestic dragon...",
  "image_path": "outputs/image_20250416_233312.png",
  "model_path": "outputs/model_20250416_233312.glb"
}
```

## ğŸ“ Project Structure

```
ai-creative-pipeline/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ core/           # Core application logic
â”‚   â”œâ”€â”€ models/         # AI models and weights
â”‚   â””â”€â”€ utils/          # Utility functions
â”œâ”€â”€ outputs/            # Generated content
â”‚   â”œâ”€â”€ images/         # 2D image outputs
â”‚   â””â”€â”€ models/         # 3D model outputs
â”œâ”€â”€ memory/             # Persistent storage
â”œâ”€â”€ config/            # Configuration files
â”œâ”€â”€ tests/            # Test suite
â””â”€â”€ docker/           # Docker configuration
```

## ğŸ› Error Handling

- Comprehensive error logging
- Graceful failure recovery
- User-friendly error messages
- Automatic retry mechanism

## ğŸ”’ Security Notes

- Local processing ensures data privacy
- No external API dependencies
- Secure file handling
- Resource usage limits

## ğŸ¤ Contributing

Contributions are welcome! Please read our [Contributing Guide](CONTRIBUTING.md) for details on:
- Code style
- Development process
- Pull request procedure

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Authors

- **Aman Kumar** - *Initial work* - [Amanastel](https://github.com/Amanastel)

## ğŸ™ Acknowledgments

- OpenFabric team for the SDK
- LLaMA team for the language model
- Contributors and testers 
